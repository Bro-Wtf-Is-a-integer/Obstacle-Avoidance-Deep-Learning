{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfdy5kopmRXa"
      },
      "source": [
        "Prepare Training Data\n",
        "1. Set up /  Prepare and format the data correctly for input into the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# License Notice\n",
        "# Copyright (c) 2025 Duc Huy Vu, Quan Hieu Tran\n",
        "#\n",
        "# This code is for personal and academic use only.\n",
        "# Only the authors may modify, distribute, or reuse it.\n",
        "# Viewing for grading purposes is allowed.\n",
        "# -----------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "Y-8K8MH__VdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsb9316TV-Lh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn                   as nn\n",
        "import torch.optim                as optim\n",
        "\n",
        "import torchvision.transforms     as transforms\n",
        "\n",
        "import numpy                      as np\n",
        "import seaborn                    as sns\n",
        "import matplotlib.pyplot          as plt\n",
        "\n",
        "from tqdm                         import tqdm\n",
        "\n",
        "from collections                  import Counter\n",
        "\n",
        "\n",
        "from sklearn.metrics              import confusion_matrix\n",
        "from sklearn.metrics              import precision_recall_fscore_support\n",
        "from torch.utils.data             import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler     import CosineAnnealingLR\n",
        "from sklearn.model_selection      import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBFSJtGjzzDs"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Mc1zym2wYN"
      },
      "outputs": [],
      "source": [
        "# Configuration for easy modification\n",
        "# Configuration for easy modification\n",
        "CONFIG = {\n",
        "    'path9': '/content/drive/MyDrive/AI Robotic/dataset/9.pkl',\n",
        "    'path8': '/content/drive/MyDrive/AI Robotic/dataset/8.pkl',\n",
        "    'path7': '/content/drive/MyDrive/AI Robotic/dataset/7.pkl',\n",
        "    'path6': '/content/drive/MyDrive/AI Robotic/dataset/6.pkl',\n",
        "    'path5': '/content/drive/MyDrive/AI Robotic/dataset/5.pkl',\n",
        "    'path4': '/content/drive/MyDrive/AI Robotic/dataset/4.pkl',\n",
        "    'path3': '/content/drive/MyDrive/AI Robotic/dataset/3.pkl',\n",
        "    'path2': '/content/drive/MyDrive/AI Robotic/dataset/2.pkl',\n",
        "    'path1': '/content/drive/MyDrive/AI Robotic/dataset/1.pkl',\n",
        "\n",
        "    'batch_size':                                             32,\n",
        "    'num_epochs':                                             60,  # Consider increasing to 10 for better training\n",
        "    'learning_rate':                                          1e-3,\n",
        "    'train_ratio':                                            0.8,\n",
        "    'num_classes':                                            9,\n",
        "    'hidden_dim':                                             256,\n",
        "    'patience':                                               100,\n",
        "    'seq_len':                                                10,\n",
        "    'class_weights':                                          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    'debug':                                                  True,\n",
        "    'use_augmentation':                                       False,  # Consider setting to True\n",
        "    'plot_loss_curves':                                       True,\n",
        "    'plot_f1_scores':                                         True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR-ZJJVu2eU_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lrJxgrAnhA6"
      },
      "source": [
        "# Part II: Load the Data\n",
        "2. Data loading\n",
        "  - Use pickle to load depth_sequences and labels from disk\n",
        "  - Or\n",
        "  - Create a Dataset class and DataLoader to feed the data into the model in batches.\n",
        "\n",
        "- Requirements:\n",
        "  - A class that inherits from torch.utils.data.Dataset:\n",
        "   - __getitem__ returns a sequence of images and the corresponding label.\n",
        "  - A DataLoader to retrieve batches during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35PxPlTSL2oz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Label mapping\n",
        "label_map = {\n",
        "    0: 'forward', 1: 'backward', 2: 'up', 3: 'down',\n",
        "    4: 'left', 5: 'right', 6: 'stop',\n",
        "    7: 'rotate_left', 8: 'rotate_right'\n",
        "}\n",
        "\n",
        "total_counter = Counter()\n",
        "\n",
        "for i in range(1, 10):\n",
        "    path = f'/content/drive/MyDrive/AI Robotic/dataset/{i}.pkl'\n",
        "    label_counter, label_str_counter, total = Counter(), Counter(), 0\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            while True:\n",
        "                try:\n",
        "                    frame = pickle.load(f)\n",
        "                    total += 1\n",
        "                    label = frame.get(\"label\")\n",
        "                    label_str = frame.get(\"label_str\")\n",
        "                    if label is not None: label_counter[label] += 1; total_counter[label] += 1\n",
        "                    if label_str: label_str_counter[label_str] += 1\n",
        "                except EOFError: break\n",
        "        print(f\" {i}.pkl | Frames: {total} | Labels: {dict(label_counter)}\")\n",
        "        print(f\" Strings: {dict(label_str_counter)}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" {i}.pkl: {e}\")\n",
        "\n",
        "# Ensure all labels 0–8 exist\n",
        "for i in range(9): total_counter.setdefault(i, 0)\n",
        "\n",
        "# Summary table\n",
        "summary = pd.DataFrame({\n",
        "    'Label': list(range(9)),\n",
        "    'Label String': [label_map[i] for i in range(9)],\n",
        "    'Count': [total_counter[i] for i in range(9)]\n",
        "})\n",
        "summary.loc[len(summary.index)] = ['', 'Total', summary['Count'].sum()]\n",
        "print(\"\\n Summary (sorted by label):\")\n",
        "\n",
        "display(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM8U4txEeubO"
      },
      "outputs": [],
      "source": [
        "def load_depth_sequences_from_pkl(pkl_path, seq_len=10, debug=False):\n",
        "    \"\"\"\n",
        "    Load a .pkl file containing UAV frame data and convert it into sequences for CNN-LSTM training.\n",
        "\n",
        "    Args:\n",
        "        pkl_path (str): Path to the .pkl file\n",
        "        seq_len (int): Number of consecutive frames in a sequence\n",
        "        debug (bool): If True, prints stats and first sample\n",
        "\n",
        "    Returns:\n",
        "        depth_sequences (list of np.array): Shape (N, seq_len, 1, H, W)\n",
        "        labels (list of int): Corresponding labels for each sequence\n",
        "    \"\"\"\n",
        "    # Load all frames\n",
        "    frames = []\n",
        "    with open(pkl_path, \"rb\") as f:\n",
        "        try:\n",
        "            while True:\n",
        "                frame = pickle.load(f)\n",
        "                frames.append(frame)\n",
        "        except EOFError:\n",
        "            pass\n",
        "\n",
        "    # Convert to sequences\n",
        "    depth_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(len(frames) - seq_len):\n",
        "        seq = frames[i:i + seq_len]\n",
        "        # Check all frames in seq are valid and labeled\n",
        "        if any(\"depth\" not in f or \"label\" not in f for f in seq):\n",
        "            continue\n",
        "        try:\n",
        "            seq_depths = np.array([f[\"depth\"] for f in seq])  # shape: (seq_len, H, W)\n",
        "            seq_depths = seq_depths[:, np.newaxis, :, :]      # add channel dim → (seq_len, 1, H, W)\n",
        "            depth_sequences.append(seq_depths)\n",
        "            labels.append(seq[-1][\"label\"])                   # label is based on last frame\n",
        "        except Exception as e:\n",
        "            if debug:\n",
        "                print(f\"Skipped sequence at {i} due to error: {e}\")\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Loaded {len(depth_sequences)} sequences of length {seq_len}\")\n",
        "        print(\"First sequence shape:\", depth_sequences[0].shape)\n",
        "        print(\"First label:\", labels[0])\n",
        "\n",
        "    return depth_sequences, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjkGJPqKewQX"
      },
      "outputs": [],
      "source": [
        "depth_seqs, labels = load_depth_sequences_from_pkl(CONFIG[\"path8\"], seq_len=10, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpeLFoKYawg8"
      },
      "source": [
        "# Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-CaNVTL0hGn"
      },
      "outputs": [],
      "source": [
        "def split_data(depth_sequences, labels, train_ratio=0.8, debug=False):\n",
        "    \"\"\"\n",
        "    Split depth sequences and labels into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        depth_sequences (list of np.array): Input sequences\n",
        "        labels (list of int): Corresponding labels\n",
        "        train_ratio (float): Ratio of training data\n",
        "        debug (bool): Print summary\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_val, y_train, y_val\n",
        "    \"\"\"\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        depth_sequences, labels,\n",
        "        train_size=train_ratio,\n",
        "        stratify=labels,  # Ensure balanced label distribution\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Training samples: {len(X_train)}\")\n",
        "        print(f\"Validation samples: {len(X_val)}\")\n",
        "        print(\"Train label distribution:\", Counter(y_train))\n",
        "        print(\"Val label distribution:\", Counter(y_val))\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v10naJre52t"
      },
      "outputs": [],
      "source": [
        "train_sequences, val_sequences, train_labels, val_labels = split_data(depth_seqs, labels, train_ratio=0.8, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S22aphsn45d"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkQNS4crtHba"
      },
      "outputs": [],
      "source": [
        "# 3. Preprocessing\n",
        "# Data Augmentation for Depth Images\n",
        "def augment_depth_image(image, debug=False):\n",
        "    \"\"\"\n",
        "    Apply random augmentations to a depth image (H x W).\n",
        "    Args:\n",
        "        image (array): Input image [H, W] (or [1, H, W])\n",
        "        debug (bool): Print debug info if True\n",
        "    Returns:\n",
        "        array: Augmented image [H, W]\n",
        "    \"\"\"\n",
        "    # Handle potential (1, H, W) input from some stages\n",
        "    if len(image.shape) == 3 and image.shape[0] == 1:\n",
        "        image = image.squeeze(0)\n",
        "\n",
        "    if len(image.shape) != 2:\n",
        "         if debug:\n",
        "             print(f\"ERROR: Augmentation received invalid shape {image.shape}, expected 2D.\")\n",
        "         raise ValueError(\"Invalid image shape for augmentation, expected 2D.\")\n",
        "\n",
        "    # Get original shape\n",
        "    H, W = image.shape\n",
        "\n",
        "    # Convert to tensor and add channel dimension → shape: (1, H, W)\n",
        "    image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    # Define augmentation transforms - ensure they work on (1, H, W)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        # Adjust translate based on actual image size, not hardcoded 0.1 for 256\n",
        "        # Max translation should be a fraction of image size\n",
        "        # Adjusted translation scale based on 256x256 assumption\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1 * (256/W), 0.1 * (256/H))),\n",
        "\n",
        "        # Add random noise\n",
        "        transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)\n",
        "    ])\n",
        "\n",
        "    # Apply transforms\n",
        "    augmented_image = transform(image)\n",
        "\n",
        "    # Remove channel dimension → shape: (H, W) and convert back to numpy\n",
        "    return augmented_image.squeeze(0).numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data"
      ],
      "metadata": {
        "id": "9SEx-y1FdJje"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M90sOBP-1IKf"
      },
      "outputs": [],
      "source": [
        "class UAVDepthDataset(Dataset):\n",
        "    def __init__(self, depth_sequences, labels, augment=True, debug=False):\n",
        "        self.depth_sequences = depth_sequences\n",
        "        self.labels = labels\n",
        "        self.augment = augment\n",
        "        self.debug = debug\n",
        "\n",
        "        if len(self.depth_sequences) == 0:\n",
        "            raise ValueError(\"Empty dataset!\")\n",
        "\n",
        "        # Validate labels\n",
        "        num_classes = CONFIG.get('num_classes', 9)\n",
        "        invalid = [l for l in labels if not (0 <= l < num_classes)]\n",
        "        if invalid:\n",
        "            raise ValueError(f\"Invalid labels: {set(invalid)}; expected in [0,{num_classes-1}]\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.depth_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      raw = self.depth_sequences[idx]  # maybe (T,1,1,H,W) or (T,1,H,W)\n",
        "      seq = []\n",
        "\n",
        "      if self.augment:\n",
        "          for frame in raw:\n",
        "              # frame: (1,1,H,W) or (1,H,W)\n",
        "              f2d = np.squeeze(frame)                # → (H,W)\n",
        "              f2d = augment_depth_image(f2d, self.debug)\n",
        "              seq.append(f2d[np.newaxis, ...])       # → (1,H,W)\n",
        "      else:\n",
        "          # just collapse all singleton dims on each frame\n",
        "          for frame in raw:\n",
        "              f2d = np.squeeze(frame)                # → (H,W)\n",
        "              seq.append(f2d[np.newaxis, ...])       # → (1,H,W)\n",
        "\n",
        "      # Now stack into (T,1,H,W)\n",
        "      proc = np.stack(seq, axis=0)\n",
        "      proc = torch.tensor(proc, dtype=torch.float32)  # (T,1,H,W)\n",
        "      lbl  = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "      return proc, lbl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU1blbP4Zbvb"
      },
      "outputs": [],
      "source": [
        "# 1) Load sequences from disk\n",
        "depth_seqs, labels = load_depth_sequences_from_pkl(\n",
        "    CONFIG[\"path8\"],\n",
        "    seq_len=CONFIG[\"seq_len\"],\n",
        "    debug=True\n",
        ")\n",
        "print(f\"Total sequences: {len(depth_seqs)}, Total labels: {len(labels)}\")\n",
        "print(f\"  • One sequence shape: {depth_seqs[0].shape}\")   # expect (seq_len, 1, H, W)\n",
        "print(f\"  • First labels: {labels[:5]}\")\n",
        "\n",
        "# 2) Split into train / val\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_seqs, val_seqs, train_lbls, val_lbls = train_test_split(\n",
        "    depth_seqs,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "print(f\"Train seqs: {len(train_seqs)}, Val seqs: {len(val_seqs)}\")\n",
        "\n",
        "# 3) Build datasets\n",
        "train_ds = UAVDepthDataset(\n",
        "    depth_sequences=train_seqs,\n",
        "    labels=train_lbls,\n",
        "    augment=CONFIG[\"use_augmentation\"]\n",
        ")\n",
        "val_ds   = UAVDepthDataset(\n",
        "    depth_sequences=val_seqs,\n",
        "    labels=val_lbls,\n",
        "    augment=False\n",
        ")\n",
        "print(f\"Dataset lengths → train: {len(train_ds)}, val: {len(val_ds)}\")\n",
        "\n",
        "# 4) Build loaders and inspect one batch\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "for batch_inputs, batch_labels in train_loader:\n",
        "    print(f\"Batch inputs shape: {batch_inputs.shape}\")   # expect (B, seq_len, 1, H, W)\n",
        "    print(f\"Batch labels shape: {batch_labels.shape}\")   # expect (B,)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientCNNEncoder"
      ],
      "metadata": {
        "id": "Joklo2N7cYPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQc6TrSsjcco"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1) Create your Dataset objects\n",
        "train_dataset = UAVDepthDataset( # Use the correct Dataset class\n",
        "    depth_sequences = train_sequences,\n",
        "    labels          = train_labels,\n",
        "    augment         = CONFIG['use_augmentation'],\n",
        "    debug           = CONFIG['debug']\n",
        ")\n",
        "val_dataset = UAVDepthDataset(   # Use the correct Dataset class\n",
        "    depth_sequences = val_sequences,\n",
        "    labels          = val_labels,\n",
        "    augment         = False,\n",
        "    debug           = CONFIG['debug']\n",
        ")\n",
        "\n",
        "# 2) Wrap them in DataLoaders\n",
        "train_loader = DataLoader(       # Use the correct DataLoader class\n",
        "    train_dataset,               # Pass the dataset object\n",
        "    batch_size  = CONFIG['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = 4,\n",
        "    pin_memory  = True\n",
        ")\n",
        "val_loader = DataLoader(         # Use the correct DataLoader class\n",
        "    val_dataset,                 # Pass the dataset object\n",
        "    batch_size  = CONFIG['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = 2,\n",
        "    pin_memory  = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    \"\"\"\n",
        "    Depthwise separable convolution block: depthwise conv + pointwise conv\n",
        "    Reduces computations compared to standard conv\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels, in_channels, kernel_size=kernel_size,\n",
        "            padding=padding, groups=in_channels, bias=False\n",
        "        )\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn(x)\n",
        "        return self.relu(x)"
      ],
      "metadata": {
        "id": "ZucNEX1Jcdc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientCNNEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Lightweight encoder using depthwise separable convolutions\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=8):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            DepthwiseSeparableConv(in_channels, 16),\n",
        "            DepthwiseSeparableConv(16, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n"
      ],
      "metadata": {
        "id": "f17ehfm1ci1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Efficient Model\n"
      ],
      "metadata": {
        "id": "j3Ls4GBId83_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientUAVNavigationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Optimized UAV navigation model:\n",
        "     - Depthwise separable convs to reduce FLOPs\n",
        "     - Global avg pooling to compress spatial dims\n",
        "     - Reduced GRU hidden size\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 9,\n",
        "        hidden_dim: int = 128,            # reduced hidden dimension\n",
        "        encoder_out: int = 8,\n",
        "        image_size: tuple = (256, 256),\n",
        "        debug: bool = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.debug = debug\n",
        "\n",
        "        # Encoder: lightweight depthwise separable convs\n",
        "        self.encoder = EfficientCNNEncoder(in_channels=1, out_channels=encoder_out)\n",
        "\n",
        "        # Feature extractor: two separable-conv blocks\n",
        "        self.cnn = nn.Sequential(\n",
        "            DepthwiseSeparableConv(encoder_out, 64),\n",
        "            nn.MaxPool2d(2),\n",
        "            DepthwiseSeparableConv(64, 128),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # Global pooling to reduce spatial dims to channel vector\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Linear projection to match GRU input size\n",
        "        self.proj = nn.Linear(128, 128)\n",
        "\n",
        "        # GRU for temporal modeling\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=128,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        # Simple attention: weighted sum over time\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (B, T, 1, H, W)\n",
        "        B, T, C, H, W = x.shape\n",
        "        # Merge batch and time for per-frame processing\n",
        "        x = x.view(B * T, C, H, W)\n",
        "\n",
        "        # Encode spatial features\n",
        "        x = self.encoder(x)            # (B*T, encoder_out, H, W)\n",
        "        x = self.cnn(x)                # (B*T, 128, H', W')\n",
        "        x = self.global_pool(x)        # (B*T, 128, 1, 1)\n",
        "        x = x.view(B, T, 128)          # (B, T, 128)\n",
        "\n",
        "        # Optional projection (identity if dims match)\n",
        "        x = self.proj(x)               # (B, T, 128)\n",
        "\n",
        "        # Temporal modeling\n",
        "        x, _ = self.gru(x)             # (B, T, hidden_dim)\n",
        "\n",
        "        # Attention pooling\n",
        "        weights = self.attn(x)         # (B, T, 1)\n",
        "        weights = self.softmax(weights)\n",
        "        context = torch.sum(weights * x, dim=1)  # (B, hidden_dim)\n",
        "\n",
        "        # Classification\n",
        "        return self.fc(context)"
      ],
      "metadata": {
        "id": "wO0bFDmyd_o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmPWEBhYogNA"
      },
      "source": [
        "#Part IV: Loss Function and Optimization\n",
        "- Set up:\n",
        "  - Loss Function: e.g., CrossEntropyLoss for classification tasks.\n",
        "  - Optimizer: e.g., Adam, SGD.\n",
        "  - Learning Rate, Epoch, Batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OMuxW6PcX9x"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "print(\"Initializing model...\")\n",
        "model = EfficientUAVNavigationModel(\n",
        "    num_classes=CONFIG['num_classes'],\n",
        "    hidden_dim=CONFIG['hidden_dim'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqYDLVl46vda"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, config):\n",
        "        self.device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model        = model.to(self.device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader   = val_loader\n",
        "        self.config       = config\n",
        "\n",
        "        # checks\n",
        "        if len(train_loader)==0 or len(val_loader)==0:\n",
        "            raise ValueError(\"Empty DataLoader!\")\n",
        "        if len(config['class_weights'])!=config['num_classes']:\n",
        "            raise ValueError(\"class_weights length mismatch\")\n",
        "\n",
        "        cw = torch.tensor(config['class_weights'], device=self.device, dtype=torch.float32)\n",
        "        self.criterion = nn.CrossEntropyLoss(weight=cw)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
        "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=config['num_epochs'])\n",
        "\n",
        "        self.train_losses     = []\n",
        "        self.val_losses       = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies   = []\n",
        "\n",
        "    def train_epoch(self):\n",
        "        self.model.train()\n",
        "        total_loss, correct, total = 0., 0, 0\n",
        "        for inputs, labels in self.train_loader:\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss    = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds==labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "        acc      = 100 * correct / max(total,1)\n",
        "        return avg_loss, acc\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        self.model.eval()\n",
        "        total_loss, correct, total = 0., 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.val_loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss    = self.criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                correct += (preds==labels).sum().item()\n",
        "                total   += labels.size(0)\n",
        "\n",
        "                all_preds.extend(preds.cpu().tolist())\n",
        "                all_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        acc      = 100 * correct / max(total,1)\n",
        "        return avg_loss, acc, all_preds, all_labels\n",
        "\n",
        "    def plot_learning_curves(self):\n",
        "        epochs = range(1, len(self.train_losses)+1)\n",
        "        plt.figure(figsize=(12,4))\n",
        "        # Loss\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.plot(epochs, self.train_losses, label='Train Loss')\n",
        "        plt.plot(epochs, self.val_losses,   label='Val Loss')\n",
        "        plt.title('Loss Curves')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "        # Accuracy\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.plot(epochs, self.train_accuracies, label='Train Acc')\n",
        "        plt.plot(epochs, self.val_accuracies,   label='Val Acc')\n",
        "        plt.title('Accuracy Curves')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def evaluate(self, labels, preds):\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, preds, average=None,\n",
        "            labels=list(range(self.config['num_classes'])),\n",
        "            zero_division=0\n",
        "        )\n",
        "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
        "            labels, preds, average='macro', zero_division=0\n",
        "        )\n",
        "        cm = confusion_matrix(labels, preds, labels=list(range(self.config['num_classes'])))\n",
        "\n",
        "        action_names = [\n",
        "            \"Forward\",\"Up\",\"Down\",\"Left\",\"Right\",\"Stop\",\n",
        "            \"Rotate Left\",\"Rotate Right\",\"Backward\"\n",
        "        ]\n",
        "        print(\"\\nPer-class metrics:\")\n",
        "        for i in range(self.config['num_classes']):\n",
        "            name = action_names[i] if i<len(action_names) else f\"Class_{i}\"\n",
        "            print(f\"{name}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.2f}\")\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                    xticklabels=action_names[:self.config['num_classes']],\n",
        "                    yticklabels=action_names[:self.config['num_classes']])\n",
        "        plt.title(\"Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
        "\n",
        "        return {\n",
        "            'precision': precision.tolist(),\n",
        "            'recall': recall.tolist(),\n",
        "            'f1': f1.tolist(),\n",
        "            'macro_f1': macro_f1,\n",
        "            'confusion_matrix': cm.tolist()\n",
        "        }\n",
        "\n",
        "    def train(self):\n",
        "        best_loss = float('inf')\n",
        "        no_improve = 0\n",
        "        for epoch in tqdm(range(self.config['num_epochs']), desc=\"Epochs\"):\n",
        "            train_l, train_acc = self.train_epoch()\n",
        "            val_l, val_acc, preds, labels = self.validate_epoch()\n",
        "\n",
        "            self.train_losses.append(train_l)\n",
        "            self.val_losses.append(val_l)\n",
        "            self.train_accuracies.append(train_acc)\n",
        "            self.val_accuracies.append(val_acc)\n",
        "            self.scheduler.step()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: Train L={train_l:.3f}, A={train_acc:.1f}% | \"\n",
        "                  f\"Val L={val_l:.3f}, A={val_acc:.1f}%\")\n",
        "\n",
        "            if val_l < best_loss:\n",
        "                best_loss = val_l\n",
        "                torch.save(self.model.state_dict(), \"best_model.pt\")\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "            if no_improve >= self.config['patience']:\n",
        "                print(\"Early stopping.\"); break\n",
        "\n",
        "        # final evaluation & plots\n",
        "        print(\"\\n--- Final Evaluation ---\")\n",
        "        _, _, preds, labels = self.validate_epoch()\n",
        "        results = self.evaluate(labels, preds)\n",
        "        self.plot_learning_curves()\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z9VP76RStcrA"
      },
      "outputs": [],
      "source": [
        "# 3) Pass the loaders—not the raw lists—into your Trainer\n",
        "trainer = Trainer(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "# 4) Train!\n",
        "results = trainer.train()\n",
        "print(\"Final eval results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kFsYNZZgJAFX"
      },
      "outputs": [],
      "source": [
        "# Download the model\n",
        "print(\"Training complete. Downloading best_model.pt...\")\n",
        "files.download('/content/best_model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}